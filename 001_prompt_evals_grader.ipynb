{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5437be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-haiku-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e788701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a new dataset\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"json\" or \"python\" or \"regex\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438ed743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset and write it to 'dataset.json'\n",
    "dataset = generate_dataset()\n",
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b89174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83809a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(test_case):\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    output = chat(messages)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bcc4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa99d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30fae983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 6.666666666666667\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcc6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"# AWS S3 URI Parser\\n\\nHere's a comprehensive solution to parse S3 object keys:\\n\\n```python\\nfrom urllib.parse import urlparse\\nfrom typing import Tuple, Optional\\n\\ndef parse_s3_uri(s3_uri: str) -> Tuple[str, str, str]:\\n    \\\"\\\"\\\"\\n    Parse an AWS S3 URI to extract bucket name, folder path, and file name.\\n    \\n    Args:\\n        s3_uri: Full S3 URI (e.g., 's3://my-bucket/folder/subfolder/file.txt')\\n    \\n    Returns:\\n        Tuple containing:\\n        - bucket_name: The S3 bucket name\\n        - folder_path: The folder path (empty string if file is at root)\\n        - file_name: The file name\\n    \\n    Raises:\\n        ValueError: If the URI format is invalid\\n    \\\"\\\"\\\"\\n    # Validate URI format\\n    if not s3_uri.startswith('s3://'):\\n        raise ValueError(f\\\"Invalid S3 URI format: {s3_uri}. Must start with 's3://'\\\")\\n    \\n    # Parse the URI\\n    parsed = urlparse(s3_uri)\\n    bucket_name = parsed.netloc\\n    \\n    if not bucket_name:\\n        raise ValueError(\\\"Bucket name is missing from S3 URI\\\")\\n    \\n    # Get the path (everything after the bucket name)\\n    full_path = parsed.path.lstrip('/')\\n    \\n    if not full_path:\\n        raise ValueError(\\\"S3 URI must contain a key (file path)\\\")\\n    \\n    # Split into folder path and file name\\n    if '/' in full_path:\\n        parts = full_path.rsplit('/', 1)\\n        folder_path = parts[0]\\n        file_name = parts[1]\\n    else:\\n        folder_path = ''\\n        file_name = full_path\\n    \\n    return bucket_name, folder_path, file_name\\n\\n\\n# Alternative solution using regex\\nimport re\\n\\ndef parse_s3_uri_regex(s3_uri: str) -> Tuple[str, str, str]:\\n    \\\"\\\"\\\"Parse S3 URI using regex pattern matching.\\\"\\\"\\\"\\n    pattern = r's3://([^/]+)/(.+)/([^/]+)$|s3://([^/]+)/([^/]+)$'\\n    match = re.match(pattern, s3_uri)\\n    \\n    if not match:\\n        raise ValueError(f\\\"Invalid S3 URI format: {s3_uri}\\\")\\n    \\n    groups = match.groups()\\n    \\n    if groups[0]:  # Pattern 1: bucket/path/file\\n        bucket_name, folder_path, file_name = groups[0], groups[1], groups[2]\\n    else:  # Pattern 2: bucket/file (no folder path)\\n        bucket_name, file_name = groups[3], groups[4]\\n        folder_path = ''\\n    \\n    return bucket_name, folder_path, file_name\\n\\n\\n# Test cases\\nif __name__ == \\\"__main__\\\":\\n    test_cases = [\\n        \\\"s3://my-bucket/folder/subfolder/file.txt\\\",\\n        \\\"s3://data-lake/2024/01/15/data.csv\\\",\\n        \\\"s3://my-bucket/file.txt\\\",\\n        \\\"s3://bucket-123/a/b/c/d/e/file.json\\\",\\n    ]\\n    \\n    print(\\\"=\\\" * 70)\\n    print(\\\"S3 URI Parser Results\\\")\\n    print(\\\"=\\\" * 70)\\n    \\n    for uri in test_cases:\\n        try:\\n            bucket, folder, filename = parse_s3_uri(uri)\\n            print(f\\\"\\\\nURI: {uri}\\\")\\n            print(f\\\"  Bucket: {bucket}\\\")\\n            print(f\\\"  Folder: {folder if folder else '(root)'}\\\")\\n            print(f\\\"  File:   {filename}\\\")\\n        except ValueError as e:\\n            print(f\\\"Error parsing {uri}: {e}\\\")\\n    \\n    # Test error cases\\n    print(\\\"\\\\n\\\" + \\\"=\\\" * 70)\\n    print(\\\"Error Handling Tests\\\")\\n    print(\\\"=\\\" * 70)\\n    \\n    error_cases =\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Parse an AWS S3 object key to extract the bucket name, folder path, and file name from a full S3 URI like 's3://my-bucket/folder/subfolder/file.txt'\",\n",
      "      \"format\": \"regex\"\n",
      "    },\n",
      "    \"score\": 6,\n",
      "    \"reasoning\": \"The core parsing logic using urlparse is excellent and production-ready, with proper error handling and clear separation of concerns. However, the solution is marred by incomplete code at the end and an unnecessarily complex regex alternative. The primary approach correctly handles the main use cases, but the incomplete test section and lack of edge case validation reduce overall reliability. The solution would be strong after fixing the syntax error and removing or improving the regex variant.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"# CloudFormation Template: S3 Bucket with Versioning and Public Access Blocked\\n\\n```json\\n{\\n  \\\"AWSTemplateFormatVersion\\\": \\\"2010-09-09\\\",\\n  \\\"Description\\\": \\\"CloudFormation template to create an S3 bucket with versioning enabled and public access blocked\\\",\\n  \\\"Resources\\\": {\\n    \\\"MyS3Bucket\\\": {\\n      \\\"Type\\\": \\\"AWS::S3::Bucket\\\",\\n      \\\"Properties\\\": {\\n        \\\"BucketName\\\": \\\"my-secure-bucket-12345\\\",\\n        \\\"VersioningConfiguration\\\": {\\n          \\\"Status\\\": \\\"Enabled\\\"\\n        }\\n      }\\n    },\\n    \\\"MyS3BucketPublicAccessBlock\\\": {\\n      \\\"Type\\\": \\\"AWS::S3::PublicAccessBlock\\\",\\n      \\\"Properties\\\": {\\n        \\\"Bucket\\\": {\\n          \\\"Ref\\\": \\\"MyS3Bucket\\\"\\n        },\\n        \\\"BlockPublicAcls\\\": true,\\n        \\\"BlockPublicPolicy\\\": true,\\n        \\\"IgnorePublicAcls\\\": true,\\n        \\\"RestrictPublicBuckets\\\": true\\n      }\\n    }\\n  },\\n  \\\"Outputs\\\": {\\n    \\\"BucketName\\\": {\\n      \\\"Description\\\": \\\"Name of the S3 bucket\\\",\\n      \\\"Value\\\": {\\n        \\\"Ref\\\": \\\"MyS3Bucket\\\"\\n      }\\n    },\\n    \\\"BucketArn\\\": {\\n      \\\"Description\\\": \\\"ARN of the S3 bucket\\\",\\n      \\\"Value\\\": {\\n        \\\"Fn::GetAtt\\\": [\\n          \\\"MyS3Bucket\\\",\\n          \\\"Arn\\\"\\n        ]\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## Key Features:\\n\\n| Feature | Details |\\n|---------|---------|\\n| **Versioning** | Enabled via `VersioningConfiguration.Status: \\\"Enabled\\\"` |\\n| **Block Public ACLs** | Prevents public access through ACLs |\\n| **Block Public Policy** | Prevents public access through bucket policies |\\n| **Ignore Public ACLs** | Ignores existing public ACLs |\\n| **Restrict Public Buckets** | Restricts all public access |\\n| **Outputs** | Provides bucket name and ARN for reference |\\n\\n## Usage:\\n\\n1. Save this as `template.json`\\n2. Deploy using AWS CLI:\\n   ```bash\\n   aws cloudformation create-stack --stack-name my-s3-stack --template-body file://template.json\\n   ```\\n\\n**Note:** Replace `\\\"my-secure-bucket-12345\\\"` with a globally unique bucket name.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a CloudFormation template JSON object that defines an S3 bucket with versioning enabled and public access blocked\",\n",
      "      \"format\": \"json\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution correctly addresses the core requirements of enabling versioning and blocking public access with proper CloudFormation syntax. However, it has a critical flaw with the hard-coded bucket name that will fail on deployment, and it misses several important security and operational best practices. The template is functional for the stated task but incomplete for production use.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"# AWS IAM Policy ARN Extractor\\n\\nHere's a comprehensive solution:\\n\\n```python\\nimport json\\nfrom typing import List\\n\\ndef extract_arns_from_policy(policy_json: str) -> List[str]:\\n    \\\"\\\"\\\"\\n    Extracts all resource ARNs from an AWS IAM policy JSON string.\\n    \\n    Args:\\n        policy_json: A JSON string representing an AWS IAM policy\\n        \\n    Returns:\\n        A list of all resource ARNs found in the policy\\n        \\n    Raises:\\n        json.JSONDecodeError: If the input is not valid JSON\\n        ValueError: If the input is not a valid IAM policy structure\\n    \\\"\\\"\\\"\\n    try:\\n        policy = json.loads(policy_json)\\n    except json.JSONDecodeError as e:\\n        raise json.JSONDecodeError(f\\\"Invalid JSON: {e}\\\", e.doc, e.pos)\\n    \\n    arns = []\\n    \\n    # Check if this is a valid policy structure\\n    if not isinstance(policy, dict):\\n        raise ValueError(\\\"Policy must be a JSON object (dictionary)\\\")\\n    \\n    # Extract ARNs from Statement array\\n    statements = policy.get(\\\"Statement\\\", [])\\n    \\n    if not isinstance(statements, list):\\n        raise ValueError(\\\"Statement must be an array\\\")\\n    \\n    for statement in statements:\\n        if not isinstance(statement, dict):\\n            continue\\n            \\n        # Get Resource field (can be string or list)\\n        resources = statement.get(\\\"Resource\\\")\\n        \\n        if resources:\\n            if isinstance(resources, str):\\n                arns.append(resources)\\n            elif isinstance(resources, list):\\n                arns.extend(resources)\\n    \\n    return arns\\n\\n\\n# Example usage and test cases\\nif __name__ == \\\"__main__\\\":\\n    # Test 1: Simple policy with single resource\\n    policy1 = \\\"\\\"\\\"{\\n        \\\"Version\\\": \\\"2012-10-17\\\",\\n        \\\"Statement\\\": [\\n            {\\n                \\\"Effect\\\": \\\"Allow\\\",\\n                \\\"Action\\\": \\\"s3:GetObject\\\",\\n                \\\"Resource\\\": \\\"arn:aws:s3:::my-bucket/*\\\"\\n            }\\n        ]\\n    }\\\"\\\"\\\"\\n    \\n    print(\\\"Test 1 - Single resource:\\\")\\n    print(extract_arns_from_policy(policy1))\\n    # Output: ['arn:aws:s3:::my-bucket/*']\\n    \\n    \\n    # Test 2: Policy with multiple resources\\n    policy2 = \\\"\\\"\\\"{\\n        \\\"Version\\\": \\\"2012-10-17\\\",\\n        \\\"Statement\\\": [\\n            {\\n                \\\"Effect\\\": \\\"Allow\\\",\\n                \\\"Action\\\": [\\\"s3:GetObject\\\", \\\"s3:PutObject\\\"],\\n                \\\"Resource\\\": [\\n                    \\\"arn:aws:s3:::my-bucket/*\\\",\\n                    \\\"arn:aws:s3:::another-bucket/*\\\"\\n                ]\\n            }\\n        ]\\n    }\\\"\\\"\\\"\\n    \\n    print(\\\"\\\\nTest 2 - Multiple resources in list:\\\")\\n    print(extract_arns_from_policy(policy2))\\n    # Output: ['arn:aws:s3:::my-bucket/*', 'arn:aws:s3:::another-bucket/*']\\n    \\n    \\n    # Test 3: Policy with multiple statements\\n    policy3 = \\\"\\\"\\\"{\\n        \\\"Version\\\": \\\"2012-10-17\\\",\\n        \\\"Statement\\\": [\\n            {\\n                \\\"Effect\\\": \\\"Allow\\\",\\n                \\\"Action\\\": \\\"ec2:DescribeInstances\\\",\\n                \\\"Resource\\\": \\\"arn:aws:ec2:us-east-1:123456789012:instance/*\\\"\\n            },\\n            {\\n                \\\"Effect\\\": \\\"Allow\\\",\\n                \\\"Action\\\": \\\"dynamodb:GetItem\\\",\\n                \\\"Resource\\\": \\\"arn:aws:dynamodb:us-east-1:123456789012:table/MyTable\\\"\\n            }\\n        ]\\n    }\\\"\\\"\\\"\\n    \\n    print(\\\"\\\\nTest 3 - Multiple statements with different resources:\\\")\\n    print(extract_arns_from_policy(policy3))\\n    # Output: ['arn:aws:ec2:us-east-1:123456789012:instance/*', 'arn:aws:dynamodb:us-east-1:123456789012:table/MyTable']\\n    \",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a Python function that takes an AWS IAM policy JSON string and returns a list of all the resource ARNs mentioned in the policy\",\n",
      "      \"format\": \"python\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution correctly implements the core requirement of extracting Resource ARNs from IAM identity-based policies and demonstrates solid engineering practices. However, it has meaningful gaps in coverage: NotResource is a legitimate policy field that should be extracted, and resource-based policies (which use different structures) are common in AWS but completely unsupported. The lack of deduplication is a minor issue but worth noting. The code is production-ready for identity-based policies but incomplete for broader IAM policy handling.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
